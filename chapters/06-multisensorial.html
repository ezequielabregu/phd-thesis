<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; El proceso multisensorial – Percepción de Distancia Aplicada a la Composición Sonora</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/07-rol-pad.html" rel="next">
<link href="../chapters/05-pvd.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-1e81d527365e20b3495763033adbcf98.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-cf245d7be09ffeafdb352d8b8bd5aa1e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-1e81d527365e20b3495763033adbcf98.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/06-multisensorial.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">El proceso multisensorial</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Percepción de Distancia Aplicada a la Composición Sonora</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://ridaa.unq.edu.ar/handle/20.500.11807/837" title="Descargar PDF" class="quarto-navigation-tool px-1" aria-label="Descargar PDF"><i class="bi bi-filetype-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Alternar modo lector">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><br></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-sistema-auditivo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El sistema auditivo como procesador espacial</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-revision-pad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Revisión de los aspectos más relevantes en el estudio de la percepción auditiva de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-distancia-musica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">La distancia como dimensión estructural en la música</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-pvd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Percepción visual de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-multisensorial.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">El proceso multisensorial</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-rol-pad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">El rol de la visión en la percepción auditiva de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-metodo-respuesta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Evaluación del método de respuesta de localización directa para medir la percepción auditiva de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-contexto-pvd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">El contexto ambiental auditivo afecta la percepción visual de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-ciencia-arte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Interdisciplina entre ciencia y arte</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-entrevistas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Entrevistas sobre el uso del espacio sonoro y la percepción de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12-conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Conclusiones finales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13-anexos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Anexos</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Índice</h2>
   
  <ul>
  <li><a href="#introducción" id="toc-introducción" class="nav-link active" data-scroll-target="#introducción"><span class="header-section-number">6.1</span> Introducción</a></li>
  <li><a href="#la-percepción-multisensorial" id="toc-la-percepción-multisensorial" class="nav-link" data-scroll-target="#la-percepción-multisensorial"><span class="header-section-number">6.2</span> La percepción multisensorial</a></li>
  <li><a href="#el-proceso-multisensorial" id="toc-el-proceso-multisensorial" class="nav-link" data-scroll-target="#el-proceso-multisensorial"><span class="header-section-number">6.3</span> El proceso multisensorial</a></li>
  <li><a href="#el-sonido-altera-aspectos-temporales-de-la-visión" id="toc-el-sonido-altera-aspectos-temporales-de-la-visión" class="nav-link" data-scroll-target="#el-sonido-altera-aspectos-temporales-de-la-visión"><span class="header-section-number">6.4</span> El sonido altera aspectos temporales de la visión</a></li>
  <li><a href="#el-sonido-altera-otros-aspectos-de-la-visión" id="toc-el-sonido-altera-otros-aspectos-de-la-visión" class="nav-link" data-scroll-target="#el-sonido-altera-otros-aspectos-de-la-visión"><span class="header-section-number">6.5</span> El sonido altera otros aspectos de la visión</a></li>
  <li><a href="#modulación-crossmodal-del-aprendizaje-y-la-adaptación" id="toc-modulación-crossmodal-del-aprendizaje-y-la-adaptación" class="nav-link" data-scroll-target="#modulación-crossmodal-del-aprendizaje-y-la-adaptación"><span class="header-section-number">6.6</span> Modulación crossmodal del aprendizaje y la adaptación</a></li>
  <li><a href="#referencias-bibliográficas" id="toc-referencias-bibliográficas" class="nav-link" data-scroll-target="#referencias-bibliográficas"><span class="header-section-number">6.7</span> Referencias bibliográficas</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">El proceso multisensorial</span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<section id="introducción" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="introducción"><span class="header-section-number">6.1</span> Introducción</h2>
<p>Por más de un siglo, el funcionamiento del cerebro en general, y la percepción en particular, ha sido concebida como altamente modular (Pascual Leone y Hamilton, 2001). Esta forma de ver la percepción ha sido relevante respecto al estudio del procesamiento visual y de cómo la visión es considerada como la modalidad dominante. Por otro lado, numerosa evidencia (especialmente en los últimos años) ha revelado que la percepción visual puede ser modificada tanto cuantitativa como cualitativamente por la presencia de información proveniente de otras modalidades. Esta modulación puede tener lugar en diferentes niveles de procesamiento y dominios perceptuales. La modulación crossmodal del procesamiento visual no está acotada a la percepción, sino que también juega un importante rol en el aprendizaje perceptual visual. Existe evidencia de que la información crossmodal puede ser utilizada para calibrar la visión y ajustar el peso relativo de las pistas visuales (Adams et al., 2004). Esta interacción podrían seguir estrategias que intentan minimizar el error perceptual estimado sobre el promedio.</p>
<p>A continuación se revisarán cuáles son los principales estudios sobre los mecanismos involucrados en la percepción multisensorial y, en particular, la relación crossmodal audiovisual. Este capítulo intenta establecer la importancia de la interacción multisensorial, la cual depende de la información proveniente de diferentes sentidos involucrados. El objetivo será subrayar la relevancia del conocimiento acerca de cómo la interacción audiovisual varía de acuerdo al contexto, para entender la bases del mecanismo de integración multisensorial y la representación del espacio en distancia.</p>
</section>
<section id="la-percepción-multisensorial" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="la-percepción-multisensorial"><span class="header-section-number">6.2</span> La percepción multisensorial</h2>
<p>Históricamente, se ha tendido estudiar las diferentes modalidades sensoriales de forma aislada, ya sea por razones prácticas o teóricas. Pero en nuestra experiencia diaria, la estimulación multisensorial es ubicua. De hecho, un creciente número de trabajos sugieren que la percepción es multisensorial, y que la interacción perceptual multisensorial es “la regla y no la excepción” (Shimojo y Shams, 2001).</p>
<p>La percepción del mundo real depende de la integración de la información multisensorial. La percepción del entorno es un aspecto ubicuo de la experiencia diaria, en donde nuestra percepción del mundo claramente se beneficia de información proveniente de múltiples modalidades. En humanos, con audición y escucha normal, la percepción del mundo exterior se basa principalmente en la visión y la audición. La habilidad para determinar de forma precisa y rápida la localización de una fuente de sonido es de una gran importancia en la vida de muchas especies. El proceso de localización del sonido también juega un rol clave en direccionar la atención hacia el objeto o el evento de interés, dado que ellos pueden ser registrados por otros sentidos, más comúnmente la visión.</p>
<p>Una percepción del entorno robusta requiere que la información proveniente de nuestros cinco sentidos sea combinada en un nivel central para producir una única percepción unificada del entorno. Los humanos poseemos múltiples sistemas sensoriales que son sensibles a los diferentes indicios perceptuales del contexto. La integración de la información a través de modalidades sensoriales expresan una importante ventaja adaptativa. Teorías recientes y evidencias presentadas en varios estudios sugieren que la combinación no ocurre de una manera rígida, sino que siguen reglas dependientes de la situación que otorgan información para ser combinada con la máxima eficiencia.</p>
<p>La integración multisensorial es caracterizada principalmente por dos fenómenos perceptuales. Primero, la mejora crossmodal ocurre cuando la precisión es incrementada por la información congruente abarcando más de una modalidad sensorial. Segundo, la ilusión crossmodal puede ocurrir cuando información incongruente abarca diferentes modalidades. Diversos trabajos han dado evidencia sustancial de que el proceso multisensorial otorga ventajas sobre el proceso unimodal. En general, estímulos multisensoriales son detectados más rápidamente que sus componentes unimodales (Fort et al., 2002; Giard y Peronnet, 1999). Apoyando esta idea, Erns y Bulthoff (2004) afirman que la clave para obtener una percepción robusta sucede cuando se combinan e integran información proveniente de múltiples modalidades sensoriales.</p>
<p>La integración de información multisensorial puede reducir la ambigüedad (Sumby y Pollack, 1954) e incrementar la precisión de la percepción de la respuesta (Talsma et al., 2010). Diversos estudios indican que las señales visuales tienden a ser localizadas con mayor precisión y con menor variabilidad que las señales auditivas (Alais y Burr, 2004; Battaglia y Jacobs, 2003). Los estímulos visuales y auditivos alineados temporal y espacialmente presentan menor desvío y variación en cuanto a su localización que usando una modalidad aislada. De hecho, la disponibilidad de diferentes señales sensoriales, y la habilidad para combinar estas señales en una manera que refleje con precisión los eventos que tienen lugar en el entorno, podría reforzar el procesamiento perceptual frente al ruido interno/externo y los sesgos perceptuales de una modalidad específica. Por ejemplo, cuando la confiabilidad de una modalidad sensorial es comprometida por el ruido o la desviación, la información proveniente de otra modalidad podría ayudar en la desambiguación de los estímulos y facilitar la percepción, o al menos hacerla útil funcionalmente.</p>
</section>
<section id="el-proceso-multisensorial" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="el-proceso-multisensorial"><span class="header-section-number">6.3</span> El proceso multisensorial</h2>
<p>En las últimas décadas ha habido un gran interés por estudiar el proceso multisensorial. Trabajos recientes han cuestionado que la percepción unisensorial ocurre antes que lo multisensorial, valiéndose de la evidencia presente en estudios comportamentales y neurofisiológicos, los cuales sugieren que el proceso multisensorial ocurre mucho antes de lo que se suponía. Un creciente número de estudios sobre interacción multisensorial ha cuestionado la visión tradicional de que las modalidades sensoriales son independientes funcionalmente.</p>
<p>Mientras que las más conocidos ejemplos de la interacción crossmodal involucran modificaciones de otras modalidades por la visión, existe un número de estudios en la literatura que reportan interacciones crossmodales en la dirección opuesta. La mayoría de estos trabajos involucran tanto modificaciones de las características temporales percibidas de estímulos visuales así como las de duración (Walker y Scott, 1981) y frecuencia (Gebhard y Mowbray, 1959; Shipley, 1964; Welch et al., 1986). Sin embargo, las características temporales no son los únicos atributos de los estímulos visuales sujetos de modificación. Por ejemplo, Stein et al.&nbsp;reportaron que la intensidad percibida de un estímulo visual es mejorada en presencia de sonido (Stein et al.&nbsp;1996). Igualmente, debemos notar que todos los reportes mencionados, respecto a la modificación de la visión por otras modalidades, involucra pequeños cambios cuantitativos en oposición al cambio radical en la calidad de percepción.</p>
<p>También existe evidencia en donde un sonido coincidente, tanto espacial como temporalmente, puede mejorar la detección visual de un estímulo degradado. El análisis de la detección de las señales revela tanto un cambio en el criterio de toma de decisiones como en la sensibilidad perceptiva (Green, 1989) causado por el sonido (Frassinetti, 2002). Una posible explicación para este efecto del sonido ha sido que el sonido provee una función general de alerta/detonante que causa un procesamiento más eficiente del estímulo concurrente en general.</p>
<p>Otro ejemplo de cómo el sistema perceptivo se enfrenta con el conflicto espacial intersensorial es el llamado “<em>efecto ventrílocuo</em>” (Howard, 1966; Thurlow, 1973; Warren y Welch, 1981) el cual hemos visto en el capítulo anterior. En este efecto, el estímulo visual y auditivo están alineados en tiempo, desplazando el estímulo visual a una distancia modesta, frecuentemente causará que el el estímulo auditivo es “capturado” por el evento visual.</p>
<p>En caso de ambigüedad o conflicto perceptivo, la entrada auditiva afecta considerablemente la evaluación percibida de un estímulo visual, a pesar de la congruencia espacial o la intensidad de los estímulos auditivos (Gebhard y Mowbray, 1959; Shipley, 1964; Welch et al., 1986). En este sentido, el sonido puede afectar la visión en el dominio temporal. Esto lo hace un sentido adaptativo, ya que la modalidad auditiva tiene mucha más resolución que la modalidad visual. La duración percibida de un estímulo visual y el intervalo entre dos eventos visuales pueden ser influenciados por el sonido (Walter y Scott, 1981).</p>
</section>
<section id="el-sonido-altera-aspectos-temporales-de-la-visión" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="el-sonido-altera-aspectos-temporales-de-la-visión"><span class="header-section-number">6.4</span> El sonido altera aspectos temporales de la visión</h2>
<p>Diversos estudios revelan que la percepción visual podría ser alterada en el dominio del tiempo por otras modalidades. La duración percibida (Walker y Scott, 1981) o la velocidad (Warren et al., 1986) en la que se presenta un estímulo visual ha mostrado que puede ser influenciada al ser acompañado de señales sonoras. La resolución temporal puede ser incluso mejorada o desmejorada ante la presencia de información sonora, dependiendo de las relaciones temporales entre el estímulo visual y el auditivo. En un estudio de Scheier et al.&nbsp;(1999) cuando dos estímulos lumínicos fueron activados en diferentes ubicaciones con un pequeño retardo de aparición (-60 a +60 ms) la precisión de la percepción temporal de las dos luces fue mejor cuando la clave visual estuvo acompañada de un estímulo auditivo, en comparación a cuando la clave visual no fue acompañada por ningún sonido. Contrariamente, la performance de los sujetos empeoró (en comparación a la condición sin sonido) cuando dos sonidos fueron insertados en el lapso temporal existente entre los dos estímulos visuales. Estos resultados son consistentes con los de otros estudios en los que un flash de luz es percibido adelantado, temporalmente, cuando es precedido de un sonido.</p>
<p>Teniendo en cuenta los casos mencionados, podemos ver que la modalidad más apropiada o eficaz, respecto a una tarea, es la que dominante en el proceso multisensorial. La visión tiene una resolución espacial muy alta, por lo que dominará en ésta tarea, en comparación a la modalidad auditiva que presenta mayor resolución temporal. La dominancia de la visión en el efecto ventrílocuo y la dominancia de la audición en tareas temporales, son consistentes con ésta hipótesis.</p>
</section>
<section id="el-sonido-altera-otros-aspectos-de-la-visión" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="el-sonido-altera-otros-aspectos-de-la-visión"><span class="header-section-number">6.5</span> El sonido altera otros aspectos de la visión</h2>
<p>La alteración de la modalidad visual por el sonido no siempre se encuentra limitada a los aspectos temporales de los estímulos visuales. La percepción auditiva puede afectar la organización perceptiva de la modalidad visual. Por ejemplo, un sonido repentino puede mejorar la detección de flashes subsiguientes en la misma ubicación (McDonald et al., 2000). También, la intensidad de un estímulo visual ha mostrado que puede incrementarse por la presencia del sonido (Stein et al., 1996). Existe evidencia de que el sonido puede alterar la interpretación de un evento visual de movimiento (Sekuler, Sekuler y Lau,1997). En este experimento de Sekuler y Lau (1997) se les presentaron a los sujetos dos claves visuales idénticas, moviéndose una contra otra. Luego, se les preguntó si habían percibido las claves visuales rebotando o traspasándose una sobre el otra. Cuando se presentó el estímulo visual sin sonido, la mayoría de los observadores reportaron una percepción de traspaso, y no de rebote. Por el contrario, cuando un sonido corto fue agregado, en el momento que las claves visuales coincidían, la percepción visual fue desviada fuertemente, a favor del movimiento de rebote (Fig. 6.1).</p>
<p><a href="../media/image11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="../media/image11.png" style="width:5.90764in;height:1.48264in"></a></p>
<p><em><strong>Figura 6.1:</strong> Ilusión visual causada por el sonido. a) La ilusión transmisión-rebote fue reportada por Sekuler et al.&nbsp;(1997). b) La ilusión de flash inducida por el sonido fue reportada por Shams et al. (2000).</em></p>
<p>La alteración de la visión por el sonido no está limitada a modulaciones de intensidad percibida o situaciones de ambigüedad con el estímulo visual. Por ejemplo, en el efecto de “<em>Ilusión de flash</em>” (Shams et al., 2000) cuando un único flash es acompañado de múltiples beeps auditivos es percibido como una ráfaga de múltiples flashes. Esto indica que el fenómeno de la ilusión del flash es en efecto una ilusión visual y no se debe a la dificultad de la tarea o a una desviación cognitiva producida por el sonido.</p>
</section>
<section id="modulación-crossmodal-del-aprendizaje-y-la-adaptación" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="modulación-crossmodal-del-aprendizaje-y-la-adaptación"><span class="header-section-number">6.6</span> Modulación crossmodal del aprendizaje y la adaptación</h2>
<p>Para tareas donde la estimación visual puede utilizar múltiples pistas, la ponderación de las pistas visuales pueden ser afectadas por cuán consistente es cada pista en relación a la pista no-visual. Las señales crossmodales también pueden mejorar la memoria visual y el aprendizaje perceptual. Por ejemplo, en un trabajo de Murray et al.&nbsp;(2004) se encontró que cuando la tarea de los sujetos consistía en juzgar si una imagen era presentada con anterioridad o por primera vez, la precisión del reconocimiento fue superior para las imágenes que que fueron inicialmente presentadas juntas con sus correspondientes sonidos (ej: imágen de una campana y el sonido “dong”), en comparación con las imágenes que fueron presentadas inicialmente sin sonido. En otras palabras, la codificación audiovisual de objetos mejora la recuperación visual.</p>
</section>
<section id="referencias-bibliográficas" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="referencias-bibliográficas"><span class="header-section-number">6.7</span> Referencias bibliográficas</h2>
<p>Adams, W. J., Graf, E. W., Ernst, M. O. Experience can change the ‘light-from-above’ prior. Nature Neuroscience 7, 1057–8 (2004).</p>
<p>Alais, D., Burr, D. The ventriloquist effect results from near- optimal bimodal integration. Curr Biol 14, 257–262 (2004).</p>
<p>Battaglia P., Jacobs R., Aslin R. Bayesian integration of visual and auditory signals for spatial localization. J Opt Soc Am 20(7), 1391–1396 (2003).</p>
<p>Ernst, M. O. y Bulthoff, H. H. Merging the sense into robust percept. Trends in Cognitive Science 8(4), 162-169 (2004).</p>
<p>Fort, A., Delpuech C., Pernier J., Giard M. H. Dynamics of cortico-subcortical cross-modal operations involved in audio-visual object detection in humans. Cereb Cortex 12, 1031–1038 (2002).</p>
<p>Frassinetti, F., Bolognini, N., Ladavas, E. Enhancement of visual perception by crossmodal visuo–auditory interaction. Experimental Brain Research 147, 332–43 (2002).</p>
<p>Gebhard, J. W., Mowbray G. H. On discriminating the rate of visual flicker and auditory flutter, Am. J. Psychol. 72, 521–528 (1959).</p>
<p>Giard M. H., Peronnet, F. Auditory-visual integration during multimodal object recognition in humans: a behavioural and electrophysiological study. J Cogn Neurosci; 11:473–490 (1999).</p>
<p>Green D. M., Swets J. A. Signal detection theory and psychophysics. Los Altos, CA: Peninsula Publishing (1989).</p>
<p>Howard I. y Pa W. <em>Human spatial orientation</em>. London, Wiley (1966).</p>
<p>McDonald, J. J., Teder-Salejarvi, W. A. y Hillyard, S. A. Involuntary orienting sound improves visual perception. Nature 407, 906-908 (2000).</p>
<p>Murray M. M., Michel C. M., Grave de Peralta R., Ortigue S., Brunet D., Gonzalez Andino S. Rapid discrimination of visual and multisensory memories revealed by electrical neuroimaging. Neuroimage 21, 125–35 (2004).</p>
<p>Pascual-Leone A., Hamilton R. The metamodal organization of the brain. Progress in Brain Research 134, 427–45 (2001).</p>
<p>Scheier, C. R., Nijhawan, R., y Shimojo, S. Sound alters visual temporal resolution [Abstract]. Investigative Ophthalmology and Visual Science 40, 41-69 (1999).</p>
<p>Sekuler, R., Sekuler, A. A. y Lau, R. Sound alters visual motion perception. Nature 385, 308 (1997).</p>
<p>Shams, L., Kamitani, Y. y Shimojo, S. Visual illusion induced by sound. Cognitive Brain Research 14, 147-152 (2002).</p>
<p>Shimojo, S. y Shams, L. Sensory modalities are not separated modalities: plasticity and interaction perceptual modality. Acoustic Science and Technology 22(2), 61-67 (2001).</p>
<p>Shipley T. Auditory flutter-driving of visual flicker, Science 145, 1328–1330 (1964).</p>
<p>Stein B. E., London N., Wilkinson L.K., Price D. D. Enhancement of perceived visual intensity by auditory stimuli: a psychophysical analysis. J. Cognit. Neurosci. 8, 497–506 (1996).</p>
<p>Sumby, W. H., y Pollack, I. Visual contribution to speech intelligibility in noise. Journal of the Acoustical Society of America 26, 212–215 (1954).</p>
<p>Talsma, D., Senkowski, D., Soto-Faraco, S. y Woldorff, M. G. The multifaceted interplay between attention and multisensory integration. Trends in Cognitive Sciences 14, 400–410 (2010).</p>
<p>Thurlow W.R., Jack C. E. Certain determinants of the “ventriloquism effect”. Perceptual and Motor Skills 36, 1171–84 (1973).</p>
<p>Walker J. T. y Scott K. J. Auditory–visual conflicts in the perceived duration of lights, tones, and gaps. Journal of Experimental Psychology: Human Perception and Performance 7, 1327–39 (1981).</p>
<p>Walker J. T. y Scott K. J. Auditory–visual conflicts in the perceived duration of lights, tones and gaps, J. Exp. Psychol.: Hum. Percept. Perform. 7, 1327–1339 (1981).</p>
<p>Warren D. H., Welch R. B., McCarthy, T. J. The role of visual–auditory “compellingness” in the ventriloquism effect: implications for transitivity among the spatial senses. Perception &amp; Psychophysics 30, 557–64 (1981).</p>
<p>Welch R. B., Duttenhurt L. D., Warren D. H. Contributions of audition and vision to temporal rate perception, Percept. Psychophys 39, 294–300 (1986).</p>
<p><strong>Trabajo de Campo y Resultados</strong></p>
<p>Desde el comienzo de la investigación respecto a la percepción de distancia nos enfocamos en abordar una nueva y efectiva metodología, que pueda solventar algunas limitaciones de métodos experimentales utilizados en las principales investigaciones previas del área (Ver Capítulos 7, 8 y 9). A diferencia del método más extendido para reportar la percepción de distancia, como lo es el reporte verbal, utilizamos un enfoque multimodal para el diseño del setup experimental para medir PAD en experimentos que se describirán a continuación.</p>
<p>El desarrollo de los dispositivos experimentales implicó una gran variedad de pruebas, a fin de verificar la confiabilidad y robustez del diseño. Por ejemplo, se han realizado diversas pruebas comparativas para comprobar cuál era el grado de precisión de percepción auditiva y visual de distancia. En el proceso de diseño de los dispositivos experimentales fue contundente evidenciar que, a pesar de presentar a los sujetos información visual muy escasa (pequeños LEDs luminosos), las claves visuales influyeron de forma notable la PAD.</p>
<p>En el primer caso, se expondrá un trabajo que estudia la influencia que tienen las claves visuales y el contexto visual en la PAD. Luego veremos las características, implementacion y ventajas de un nuevo dispositivo experimental utilizado para realizar experimentos de percepción de distancia diseñado desde un enfoque multimodal. Finalmente, se expondrán resultados de una investigación multimodal en el sentido opuesto; es decir, de qué manera el contexto auditivo afecta la percepción visual de distancia.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/05-pvd.html" class="pagination-link" aria-label="Percepción visual de distancia">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Percepción visual de distancia</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/07-rol-pad.html" class="pagination-link" aria-label="El rol de la visión en la percepción auditiva de distancia">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">El rol de la visión en la percepción auditiva de distancia</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Dr. Ezequiel Abregú
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>