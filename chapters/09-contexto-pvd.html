<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; El contexto ambiental auditivo afecta la percepción visual de distancia – Percepción de Distancia Aplicada a la Composición Sonora</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/10-ciencia-arte.html" rel="next">
<link href="../chapters/08-metodo-respuesta.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-1e81d527365e20b3495763033adbcf98.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-cf245d7be09ffeafdb352d8b8bd5aa1e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-1e81d527365e20b3495763033adbcf98.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/09-contexto-pvd.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">El contexto ambiental auditivo afecta la percepción visual de distancia</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Percepción de Distancia Aplicada a la Composición Sonora</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://ridaa.unq.edu.ar/handle/20.500.11807/837" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-filetype-pdf"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Alternar modo oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Alternar modo lector">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><br></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-sistema-auditivo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El sistema auditivo como procesador espacial</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-revision-pad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Revisión de los aspectos más relevantes en el estudio de la percepción auditiva de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-distancia-musica.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">La distancia como dimensión estructural en la música</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-pvd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Percepción visual de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-multisensorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">El proceso multisensorial</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/07-rol-pad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">El rol de la visión en la percepción auditiva de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/08-metodo-respuesta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Evaluación del método de respuesta de localización directa para medir la percepción auditiva de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/09-contexto-pvd.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">El contexto ambiental auditivo afecta la percepción visual de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/10-ciencia-arte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Interdisciplina entre ciencia y arte</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/11-entrevistas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Entrevistas sobre el uso del espacio sonoro y la percepción de distancia</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/12-conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Conclusiones finales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/13-anexos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Anexos</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Índice</h2>
   
  <ul>
  <li><a href="#introducción" id="toc-introducción" class="nav-link active" data-scroll-target="#introducción"><span class="header-section-number">9.1</span> Introducción</a></li>
  <li><a href="#procedimientos-experimentales" id="toc-procedimientos-experimentales" class="nav-link" data-scroll-target="#procedimientos-experimentales"><span class="header-section-number">9.2</span> Procedimientos experimentales</a>
  <ul class="collapse">
  <li><a href="#entornos-de-prueba" id="toc-entornos-de-prueba" class="nav-link" data-scroll-target="#entornos-de-prueba"><span class="header-section-number">9.2.1</span> Entornos de prueba</a></li>
  <li><a href="#participantes" id="toc-participantes" class="nav-link" data-scroll-target="#participantes"><span class="header-section-number">9.2.2</span> Participantes</a></li>
  </ul></li>
  <li><a href="#procedimiento-experimental-general" id="toc-procedimiento-experimental-general" class="nav-link" data-scroll-target="#procedimiento-experimental-general"><span class="header-section-number">9.3</span> Procedimiento experimental general</a></li>
  <li><a href="#métodos-de-estadística" id="toc-métodos-de-estadística" class="nav-link" data-scroll-target="#métodos-de-estadística"><span class="header-section-number">9.4</span> Métodos de estadística</a></li>
  <li><a href="#resultados" id="toc-resultados" class="nav-link" data-scroll-target="#resultados"><span class="header-section-number">9.5</span> Resultados</a>
  <ul class="collapse">
  <li><a href="#experimento-1" id="toc-experimento-1" class="nav-link" data-scroll-target="#experimento-1"><span class="header-section-number">9.5.1</span> Experimento 1</a></li>
  <li><a href="#experimento-2" id="toc-experimento-2" class="nav-link" data-scroll-target="#experimento-2"><span class="header-section-number">9.5.2</span> Experimento 2</a></li>
  </ul></li>
  <li><a href="#discusión" id="toc-discusión" class="nav-link" data-scroll-target="#discusión"><span class="header-section-number">9.6</span> Discusión</a></li>
  <li><a href="#conclusiones" id="toc-conclusiones" class="nav-link" data-scroll-target="#conclusiones"><span class="header-section-number">9.7</span> Conclusiones</a></li>
  <li><a href="#referencias-bibliográficas" id="toc-referencias-bibliográficas" class="nav-link" data-scroll-target="#referencias-bibliográficas"><span class="header-section-number">9.8</span> Referencias bibliográficas</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">El contexto ambiental auditivo afecta la percepción visual de distancia</span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p>En este capítulo mostramos que la Percepción Visual de Distancia (PVD) está influenciada por el contexto ambiental auditivo a través de señales relacionadas con la reverberación. Realizamos dos experimentos de PVD en dos salas oscuras con tiempos de reverberación extremadamente diferentes: una cámara anecoica y una sala reverberante. Los resultados del primer experimento muestran que los sujetos asignados a la sala reverberante sobrestimaron la distancia de los objetivos en comparación a los sujetos asignados a la cámara anecoica. Además, se encontró una correlación positiva entre la distancia máxima percibida y el tamaño de la habitación (percibida auditivamente). Se realizó un segundo experimento en el que los mismos sujetos del Experimento 1 fueron intercambiados entre habitaciones. Se encontró que los sujetos conservaron las respuestas del experimento anterior siempre que fueran compatibles con la percepción del ambiente en el que se encontraban; caso contrario, la distancia percibida estuvo sesgada en función de los límites de la habitación (percibidos auditivamente). Los resultados de ambos experimentos mostraron que el ambiente auditivo puede influir en la PVD, presumiblemente a través de señales de reverberación relacionadas con la percepción del tamaño de la habitación.</p>
<section id="introducción" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="introducción"><span class="header-section-number">9.1</span> Introducción</h2>
<p>La percepción visual de la distancia egocéntrica a un objetivo (Percepción Visual a Distancia, o PVD) se ha estudiado desde los tiempos de Leonardo da Vinci (1651) hasta nuestros días, donde sigue siendo objeto de numerosos y diversos estudios. La PVD ha sido estudiada en espacios exteriores e interiores en condiciones de campo abierto y de laboratorio, utilizando tanto entornos virtuales y como ambientes reales (Cutting y Vishton, 1995; Howard, 2012). Como hemos visto en el Capítulo 5, las escenas visuales contienen muchas fuentes de información diferentes (binoculares y monoculares) de distancia tales como: tamaño relativo, interposición, declinación angular, perspectiva, paralaje de movimiento, disparidad binocular y convergencia, entre otros (Semmlow y Heerema, 1979; Sousa et al., 2010). La evidencia acumulada ha demostrado que, en ambientes bien iluminados, donde hay múltiples señales visuales disponibles, la PVD es bastante precisa para objetivos de hasta 20 m de distancia (Thomson, 1983; Fukusima et al., 1997). Sin embargo, cuando las señales visuales están restringidas (por ejemplo, mediante la reducción de la iluminación ambiental), la percepción es menos precisa (Gogel, 1961; Philbeck y Loomis, 1997). Este último resultado sugiere que la información proporcionada por el lugar donde se localiza el sujeto y el objetivo, que denominamos <em>información contextual medioambiental</em>, también puede influir en la percepción de objetos y eventos que se presentan en él.</p>
<p>En esta línea, y como hemos visto, estudios recientes han demostrado que, incluso en presencia de múltiples señales visuales, la PVD puede ser influenciada por el contexto ambiental visual. Además, la PVD de objetos familiares en entornos naturales está condicionada por la estructura del campo visual circundante (Stefanucci et al., 2005; Lappin et al., 2006). Por ejemplo, Lappin et al.&nbsp;(2006), mostró que tanto la exactitud como la precisión de los juicios de distancia mostraron diferencias utilizando tres tipos de ambientes con múltiples señales visuales: un vestíbulo, un pasillo y un espacio abierto con césped. Además, Witt et al.&nbsp;(2007) demostró que, tanto en espacios interiores como en exteriores, el espacio influye en la PVD más allá del tipo de objetivo utilizado. Finalmente, Stefanucci et al.&nbsp;(2005) reportaron que la PVD puede ser influenciada por la inclinación del terreno: los participantes percibieron la distancia a los objetivos a mayores distancias en terreno escarpado que en terreno plano. Estos estudios demuestran que las fuentes de información que brinda el contexto espacial sirven como complemento de las claves de PVD clásicas.</p>
<p>Es interesante analizar la influencia del contexto ambiental en la PDV dentro del marco de las teorías perceptivas de integración y combinación sensorial (Proffit, 2008). Como vimos en el Capítulo 6, la integración sensorial se refiere al procesamiento de información sobre el mismo aspecto (redundante) de alguna propiedad ambiental: en la PVD, este hecho se da en las distintas señales de distancia proporcionadas por el objetivo visual. Por otro lado, la combinación sensorial se refiere al procesamiento de información sobre aspectos complementarios (no redundantes) de las propiedades ambientales observadas: en este caso, estaría representada por la información proporcionada por el medio ambiente, los objetos circundantes, y por conocimiento previo, entre otros. Estas fuentes de información son recolectadas por nuestro cerebro con el objetivo de reducir la incompletitud inherente de nuestra percepción del mundo. Curiosamente, tanto la integración como la combinación sensorial son estrategias útiles para permitir la cooperación e interacción entre las diferentes modalidades perceptivas especialmente cuando una modalidad no es suficiente para producir estimaciones robustas.</p>
<p>Un ejemplo reconocido de integración audiovisual es el efecto ventrílocuo, en el que la presencia de un estímulo visual localizado polariza la localización en ángulo de una fuente de sonido (Bingham, 1998; Rieser, 1995). Como vimos en el Capítulo 6 este tipo de integración también se ha demostrado para visual-propioceptivo (Bruggerman y Warren, 2010), visual-táctil (Bingham et al., 2014) y visual-háptico (Ernst y Bulthoff, 2004) interacciones.</p>
<p>En cuanto a la combinación sensorial multimodal, estudios recientes han demostrado que la información contextual puede afectar la percepción de la distancia auditiva de manera multimodal. Por ejemplo, Calcagno et al. (2012) demostraron que la información visual sobre contextual aumenta la precisión de los juicios de distancia auditiva incluso cuando la fuente de sonido no es visible. Los resultados de este estudio también muestran que la PAD es significativamente mejor si se permite a los participantes observar la sala experimental antes de realizar el experimento de PAD en completa oscuridad. Como vimos en los capítulos anteriores, en este estudio se planteó la hipótesis de que la distancia percibida a la fuente sonora es calibrada por información relacionada con el tamaño de la sala experimental. Dicha hipótesis se encuentra en línea con un estudio de Gajewsky et al.&nbsp;(Recanzone, 1998; Lewald, 2002), en donde se reportó que la representación del espacio circundante puede servir como una referencia espacial estructurada en la cual se integran las señales de distancia. Como consecuencia, el marco de referencia proporcionado por el entorno puede contribuir a la escala de distancia percibida, restringiendo o ampliando la respuesta de estimación de distancia. En un artículo reciente, Kolarik et al.&nbsp;(2013) reafirmaron esta hipótesis observando una correlación positiva entre la distancia perceptiva auditiva y la percepción del tamaño de la sala también mediante la modalidad auditiva. Los resultados de este estudio sugieren que el contexto auditivo ambiental también influye en la percepción auditiva de la distancia.</p>
<p>La información del contexto auditivo (asociada principalmente a la información brindada por la reverberación) ha demostrado ser útil para la percepción del espacio circundante. Por ejemplo, los oyentes humanos pueden reconocer de forma precisa fotografías de habitaciones mediante sus correspondientes grabaciones binaurales (Hay, 1965). Además, se ha reportado que sujetos con los ojos vendados pueden distinguir el tamaño de una habitación utilizando el voz hablada y otros sonidos reflejados por las superficies (Pavani, 2000). Diversos estudios han encontrado una relación directa entre la reverberación y la percepción del tamaño de una sala: mayor tiempo de reverberación se asocia constantemente con salas más grandes (Alais y Burr, 2004; Ernst y Banks, 2002; Gajewski, 2014). En resumen, aunque no seamos conscientes de ello, en la experiencia cotidiana los humanos empleamos una gran cantidad de información auditiva para percibir el entorno, complementando la información de otros sentidos.</p>
<p>De acuerdo a la evidencia presentada, nos preguntamos si la distancia percibida a un objetivo visual puede ser influenciado por la información del contexto ambiental procedente de la modalidad auditiva. Por ejemplo, si la información visual del entorno afecta la percepción de la distancia a un objeto auditivo, ¿podría ser verdadero su opuesto? En otras palabras, ¿es posible, bajo ciertas condiciones, obtener una representación del entorno a través de la información auditiva, que a su vez influya en la PVD?</p>
<p>Para responder estas preguntas investigamos si el contexto ambiental auditivo influye en la distancia percibida de los objetos luminosos ubicados en dos salas con tiempos de reverberación extremadamente diferentes: una cámara anecoica y una habitación reverberante. Se plantea la hipótesis de que la percepción de distancia visual podría estar sesgada hacia una estimación del tamaño del espacio circundante, obtenido principalmente a través de señales auditivas.</p>
<p><a href="../media/image20.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="../media/image20.png" style="width:5.75392in;height:7.89006in"></a></p>
<p><strong>Figura 9.1:</strong> <em>Diagrama de la instalación experimental en el Laboratorio de Acústica y Luminotecnia. Se observa la habitación reverberante (C), la cámara anecoica (D), el camino recorrido por los sujetos (con los ojos cubiertos) durante los experimentos desde que fueron recibidos (A) a la sala de recepción (B, donde fueron informados). Ya ambas salas de pruebas (línea roja y flechas). También se muestran las estaciones experimentales y el diseño del montaje experimental en ambas salas.</em></p>
</section>
<section id="procedimientos-experimentales" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="procedimientos-experimentales"><span class="header-section-number">9.2</span> Procedimientos experimentales</h2>
<section id="entornos-de-prueba" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="entornos-de-prueba"><span class="header-section-number">9.2.1</span> Entornos de prueba</h3>
<p>El estudio se realizó en el Laboratorio de Acústica y Luminotecnia (LAL) de la Comisión de Investigaciones Científicas de la Provincia de Buenos Aires (CIC-BA). El LAL tiene dos habitaciones con tiempos de reverberación muy diferentes (ver Tabla 9.1): (a) una cámara anecoica (media T = 0.12 s) y (b) una habitación reverberante (media T = 3.9 s).</p>
<table class="caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 32%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Banda (Hz)</th>
<th style="text-align: left;"><em>T<sub>20</sub></em> (s)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">Cámara Reverberante</td>
<td>Cámara Anecoica</td>
</tr>
<tr class="even">
<td style="text-align: left;">50</td>
<td style="text-align: left;">7.95</td>
<td>-</td>
</tr>
<tr class="odd">
<td style="text-align: left;">63</td>
<td style="text-align: left;">7.58</td>
<td>-</td>
</tr>
<tr class="even">
<td style="text-align: left;">80</td>
<td style="text-align: left;">5.92</td>
<td>0.42</td>
</tr>
<tr class="odd">
<td style="text-align: left;">100</td>
<td style="text-align: left;">5.58</td>
<td>0.24</td>
</tr>
<tr class="even">
<td style="text-align: left;">125</td>
<td style="text-align: left;">5.18</td>
<td>0.23</td>
</tr>
<tr class="odd">
<td style="text-align: left;">160</td>
<td style="text-align: left;">5.39</td>
<td>0.24</td>
</tr>
<tr class="even">
<td style="text-align: left;">200</td>
<td style="text-align: left;">4.43</td>
<td>0.14</td>
</tr>
<tr class="odd">
<td style="text-align: left;">250</td>
<td style="text-align: left;">4.64</td>
<td>0.10</td>
</tr>
<tr class="even">
<td style="text-align: left;">315</td>
<td style="text-align: left;">4.57</td>
<td>0.17</td>
</tr>
<tr class="odd">
<td style="text-align: left;">400</td>
<td style="text-align: left;">4.17</td>
<td>0.10</td>
</tr>
<tr class="even">
<td style="text-align: left;">500</td>
<td style="text-align: left;">3.78</td>
<td>0.12</td>
</tr>
<tr class="odd">
<td style="text-align: left;">630</td>
<td style="text-align: left;">3.78</td>
<td>0.12</td>
</tr>
<tr class="even">
<td style="text-align: left;">800</td>
<td style="text-align: left;">3.70</td>
<td>0.08</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1000</td>
<td style="text-align: left;">3.81</td>
<td>0.08</td>
</tr>
<tr class="even">
<td style="text-align: left;">1250</td>
<td style="text-align: left;">3.89</td>
<td>0.09</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1600</td>
<td style="text-align: left;">3.78</td>
<td>0.09</td>
</tr>
<tr class="even">
<td style="text-align: left;">2000</td>
<td style="text-align: left;">3.33</td>
<td>0.11</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2500</td>
<td style="text-align: left;">2.95</td>
<td>0.09</td>
</tr>
<tr class="even">
<td style="text-align: left;">3150</td>
<td style="text-align: left;">2.58</td>
<td>0.09</td>
</tr>
<tr class="odd">
<td style="text-align: left;">4000</td>
<td style="text-align: left;">2.15</td>
<td>0.09</td>
</tr>
<tr class="even">
<td style="text-align: left;">5000</td>
<td style="text-align: left;">1.75</td>
<td>0.10</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6300</td>
<td style="text-align: left;">1.43</td>
<td>0.09</td>
</tr>
<tr class="even">
<td style="text-align: left;">8000</td>
<td style="text-align: left;">1.03</td>
<td>0.10</td>
</tr>
<tr class="odd">
<td style="text-align: left;">10000</td>
<td style="text-align: left;">0.80</td>
<td>0.10</td>
</tr>
<tr class="even">
<td style="text-align: left;">Mean across 400-1250 Hz</td>
<td style="text-align: left;">3.86</td>
<td>0.10</td>
</tr>
</tbody>
</table>
<p><strong>Tabla 9.1</strong>: <em>Tiempo de reverberación medido (T60) para la cámara anecoica y la reverberante en la posición donde los sujetos se encontraban sentados.</em></p>
<p>La cámara anecoica tenía un volumen igual a 7,00 x 6,90 x 5,90 m (longitud x ancho x altura) y un espacio de trabajo libre igual a 5,40 x 5,30 x 4,30 m. La sala reverberante era un poliedro irregular de siete superficies, aproximadamente equivalente a una caja rectangular de 7 x 8 x 4 m de tamaño, con un volumen igual a 189 m<sup>3</sup>. Para detalles exactos de ambas cámaras ver (Sandvad, 1999; McGrath et al., 1999). Ambas habitaciones estaban ubicadas en el mismo pasillo presentando sus puertas enfrentadas (ver Fig. 9.1). Dos montajes experimentales idénticos fueron montados uno en cada habitación, situado en la misma posición relativa con respecto a la puerta.</p>
</section>
<section id="participantes" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="participantes"><span class="header-section-number">9.2.2</span> Participantes</h3>
<p>Un total de setenta y cinco voluntarios (19 mujeres y 56 hombres) participaron en los experimentos. Ninguno tuvo conocimiento previo de las salas de experimentación o de las instalaciones, ni se informó de ninguna característica de las habitaciones. Todos los sujetos fueron naive para los propósitos del estudio, tenían una visión normal o corregida a la normal (50 y 25 sujetos, respectivamente) e informaron no tener problemas auditivos. Las edades oscilaron entre 19 y 50 años (promedio = 25.0 años, s = 5.9 años). Los experimentos fueron realizados con el consentimiento escrito de cada sujeto, siguiendo el Código de Ética de la Asociación Médica Mundial (Declaración de Helsinki) y aprobados por el Comité de Ética de la Universidad Nacional de Quilmes. Todos los participantes informaron por escrito su consentimiento y no recibieron ningún pago por su tiempo. Los participantes fueron reclutados a través de anuncios distribuidos a través de grupos de correo electrónico o diversas redes sociales.</p>
<p>Los participantes fueron asignados aleatoriamente a dos grupos: los sujetos asignados al Grupo 1 realizaron el Experimento 1 en la cámara anecoica (n = 37) mientras que los sujetos asignados al Grupo 2 lo realizaron en la habitación reverberante (n = 38). En el Experimento 2, los sujetos se intercambiaron entre habitaciones: los sujetos del Grupo 1 realizaron el Experimento 2 en la sala reverberante, mientras que los sujetos del Grupo 2 lo realizaron en la cámara anecoica. Por esta razón, nos referimos al Grupo 1 como A → R, y al Grupo 2 como R → A.</p>
</section>
</section>
<section id="procedimiento-experimental-general" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="procedimiento-experimental-general"><span class="header-section-number">9.3</span> Procedimiento experimental general</h2>
<p>Cada participante fue recibido por el experimentador en el hall de entrada (punto A en la figura 9.1) y llevado a la sala de recepción (B) donde recibió instrucciones iniciales sobre la tarea. Las instrucciones fueron escritas con el fin de controlar la variabilidad en la comprensión de la tarea por los sujetos. En este punto, y con el fin de inducir la familiaridad con el objetivo, el participante fue capaz de tocar y ver un modelo idéntico de los objetivos visuales empleados en la tarea. El conocimiento previo del objetivo podría servir como una señal para la distancia visual, dado el principio de la distancia de tamaño invariancia (Mershon, 1989). De esta manera, el experimentador le vendo los ojos al participante en la sala de recepción (B) para luego ser llevado a la habitación asignada para el Experimento 1 (C o D), donde estuvo sentado en la posición cero. Después de que el participante se ubicó en la silla experimental, el experimentador salió de la habitación y las luces se apagaron, permaneciendo de esta forma hasta la finalización del experimento.</p>
<p>La línea roja de la Figura 9.1 indica la trayectoria recorrida por los sujetos desde que fueron recibidos hasta que fueron despedidos después de completar todo el experimento. Para que los participantes de ambos grupos siguieran un trayecto similar fue fundamental que ambas habitaciones estuvieran situadas frente a frente, sumado a la idéntica ubicación de las instalaciones dentro de cada habitación. Este hecho permitió minimizar las diferencias en la información propioceptiva a través de las distintas condiciones.</p>
<p>Antes de iniciar el experimento, se pidió al participante que se quite la venda de los ojos. Con el fin de exponer el sujeto a las características acústicas de la sala, se reprodujo una grabación con las instrucciones del experimento a través de un altavoz situado a 70 cm delante del participante, a una altura de 1 m. El dispositivo experimental también tenía un micrófono en la sala permitiendo la comunicación en tiempo real entre el experimentador y el participante. Estudios anteriores han demostrado que las señales de voz son estímulos efectivos con el fin de inducir un sentido espacial del medio ambiente a través de la audición (Alais y Burr, 2004; Calcagno et al., 2012).</p>
<p>La luminancia de cada objetivo se ajustó a un valor de 0,18 lux medido a una distancia de 10 cm (radiómetro portátil ILT 1400-A, International Light Technologies Inc.). Este valor, por una parte, aseguró que los blancos fueran claramente distinguibles y, por otra, impidió la iluminación de cualquier otra superficie en las habitaciones (por ejemplo, paredes, piso, etc). Los objetivos también fueron rodeados con tela opaca negra, con el fin de minimizar la iluminación de tales superficies. Además, para asegurarse de que cada habitación fue percibida totalmente oscura, después de la adaptación del ojo, dos experimentadores realizaron, como si fueran sujetos, el procedimiento completo en ambas salas. Finalmente, a cada participante se le pidió que informara sobre cualquier fuente de luz en la sala además de los objetivos. Ninguno de los participantes informó la presencia de fugas de luz no deseadas durante el experimento.</p>
<p>Los estímulos visuales utilizados fueron unos cuadrados de acrílico, de tamaño 5 x 5 cm. Cada objetivo fue iluminado por cuatro LEDs montados en su parte posterior la cual proporcionaba luz difusa. Los estímulos se colocaron delante del participante (0º acimut) a una altura de 1,50 m (aproximadamente la altura de la cabeza del sujeto, con una elevación aproximada de 0º). El sistema experimental consistió en una matriz lineal de cinco estímulos visuales, situados a D = 2, 3, 4, 5 y 6 metros de la posición del sujeto (Figura 9.1). Cada estímulo fue montado sobre un soporte metálico. Para evitar la obstrucción visual entre los estímulos, se utilizaron para mover los objetivos fuera de la línea de visión del participante. El ruido blanco (500 ms de duración) se presentó a través del altavoz antes de cada ensayo, con el fin de enmascarar ruido de los servomotores, lo que podría actuar como una señal para la distancia objetivo. El sonido enmascarante también contribuyó a exponer el sujeto a las características acústicas de la habitación. Los blancos fueron encendidos sólo después de que alcanzaron su posición final y duraron 2 segundos.</p>
<p>Después de cada presentación, se le pidió a los participantes que expresaran verbalmente la distancia aparente al objetivo visual. Las respuestas fueron registradas en una computadora y transcriptas manualmente en una hoja de datos por el experimentador (que permaneció fuera de la sala hasta la finalización del procedimiento, véase la Fig. 9.1). Cada objetivo se presentó cinco veces por cada distancia de prueba (25 ensayos en total) en orden aleatorio. Los participantes realizaron una sola respuesta verbal por ensayo y no recibieron ninguna información sobre la corrección de sus respuestas. Después de completar la tarea de PVD, el sujeto fue vendado y devuelto a la sala de recepción (B). Allí completó un formulario con su estimación de largo, ancho y alto de la habitación donde se realizó el experimento. Después de completar este formulario, el sujeto se volvió a taparse los ojos y se introdujo en la otra habitación asignada para el Experimento 2, donde se repitió idénticamente el procedimiento (incluyendo la reproducción de las instrucciones a través del altavoz).</p>
</section>
<section id="métodos-de-estadística" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="métodos-de-estadística"><span class="header-section-number">9.4</span> Métodos de estadística</h2>
<p>Todos los datos se analizaron considerando un nivel de significación del 5%. Las curvas visuales de percepción de distancia obtenidas en las dos salas se compararon mediante análisis de varianza en el logaritmo de las respuestas, con los factores "distancia objetivo" (dentro de los sujetos) y "sala" (entre o dentro de los sujetos, Caso) como factores fijos. Los datos del Experimento 1 se compararon entre los grupos, mientras que los datos del Experimento 2 se compararon con los datos del Experimento 1 dentro de cada grupo. En el caso de que la esfericidad fue violada, los valores de p reportados corresponden a los obtenidos después de aplicar la corrección de Greenhouse-Geiser (observe que las violaciones de la esfericidad sólo pueden ocurrir para "distancia objetivo" y para la interacción entre "distancia objetivo", pero no para "habitación"). Los datos de tamaño de la habitación individual se compararon entre las habitaciones por medio de t-tests, la hipótesis nula de que las respuestas en la sala de reverberación fueron más pequeñas (en comparación con los grupos), igual o mayor que las respuestas en la cámara anecoica. La hipótesis nula para estos análisis se derivó de pruebas anteriores que asocian la reverberación más alta con un mayor tamaño de la habitación percibida, como se describe en la Introducción. Los datos se transformaron en el registro antes de la prueba, con el fin de lograr la igualdad de varianza a través de la distancia objetivo. Dado que la sustracción entre dos números en log-scale corresponde al logaritmo de su relación en escala lineal [i.e., log(x<sub>A</sub>) - log(x<sub>B</sub>) = log(x<sub>A</sub>/x<sub>B</sub>), (Eq. 1)], (Eq. Entre el tamaño de la habitación (en escala de log) se transformaron en "relaciones reverberantes a anecoicas" medias, calculadas como e ^ (diferencia de medias reportada por la prueba t). Esta magnitud se puede interpretar fácilmente ya que se espera que sea mayor que uno en caso de rechazo de la hipótesis nula. El post-análisis en las curvas de PVD se realizó mediante t-test pareadas en t de las respuestas log individuales, siendo la hipótesis nula igual a la de los datos del tamaño de la sala. La hipótesis nula en este caso se derivó de nuestra hipótesis de que la distancia objetivo en la sala reverberante se percibirá más lejos que en la cámara anecoica. La significancia se controló mediante el procedimiento de Holm-Bonferroni (Gajewski et al., 2014) para cinco comparaciones: dado que había cinco distancias objetivo, cinco es el número máximo de comparaciones posibles entre ambas salas.</p>
</section>
<section id="resultados" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="resultados"><span class="header-section-number">9.5</span> Resultados</h2>
<section id="experimento-1" class="level3" data-number="9.5.1">
<h3 data-number="9.5.1" class="anchored" data-anchor-id="experimento-1"><span class="header-section-number">9.5.1</span> Experimento 1</h3>
<p>Los sujetos fueron asignados al azar a una de las dos habitaciones: una cámara anecoica (Grupo 1, n = 37, tiempo de reverberación medio T = 0,12 s) y una habitación reverberante (Grupo 2, n = 38; T = 3,9 s; S1). Ninguno de los sujetos tuvo conocimiento previo de ninguna de las dos salas de experimentación o sus dimensiones. Se les presentó a los sujetos como claves visuales unos cuadrados luminosos de tamaño 5 x 5 cm, situados a distancias D = 2, 3, 4, 5 y 6 m (medidos desde el asiento del sujeto). La luminosidad de la clave visual se ajustó para evitar que cualquier superficie de la habitación fuese iluminada. De esta manera nos aseguramos que, durante la tarea, los participantes sólo pudieran ver los objetivos visuales. En cada ensayo, los sujetos debían reportar verbalmente la distancia percibida al objetivo. Las instrucciones, reproducidas a través de un altavoz, así como los informes verbales de los participantes, fueron algunos de los estímulos auditivos utilizados para exponerlos a las características acústicas de cada sala.</p>
<p>La Figura 9.2a presenta la distancia media percibida (+/- SEM) como una función de la distancia al objetivo para ambos grupos. En ambas habitaciones la respuesta fue casi lineal y las pendientes fueron bastante similares (cámara anecoica: 0,94 +/- 0,08; sala de reverberante: 1,06 +/- 0,10). Además, ambos grupos subestimaron la distancia al objetivo para todas las distancias de prueba. Curiosamente, los participantes que realizaron el experimento en la sala reverberante (Grupo 2) percibieron los objetivos visuales a mayor distancia que los participantes asignados a la cámara anecoica (Grupo 1). Por ejemplo, las claves visuales situadas a 5 y 6 m difirieron en 68 y 85 cm respectivamente, dando como resultado una diferencia relativa de aproximadamente 17%. La significancia estadística de esta diferencia se evaluó mediante un ANOVA de medidas repetidas sobre los logaritmos de las respuestas, lo que reveló un efecto significativo de la habitación [F (1,73) = 4,11, p = 0,046] y de la distancia objetivo [F (4, 292) = 627, p &lt;0,001] pero no de su interacción [F (4, 292) = 0,97, p = 0,37].</p>
<p>Con el objetivo de probar si existe una relación entre la PVD y la percepción del tamaño de la habitación, después de completar la tarea de PVD le pedimos a los participantes que estimen el tamaño de la habitación (ver <em>Métodos</em> para más detalles). Los resultados se representan en la Figura 9.2b (volumen percibido medio de la habitación) y Figura 9.2c (largo, ancho y altura percibidas media y la individual). La sala reverberante se percibió significativamente mayor que la cámara anecoica [t (73) = 1,83, p = 0,0355, razón media = 1,71]. Con el objetivo de comprobar esta asociación, también se analizó la correlación entre el tamaño de la habitación percibida y la máxima distancia percibida (MDP) en escala log-log (véase [39]). Se obtuvo una correlación significativa positiva entre la MDP y el volumen percibido en ambas salas (cámara anecoica: r = 0,48, p = 0,0029, sala reverberante: r = 0,65, p = 1,2 x 10-5)</p>
<p><a href="../media/image21.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="../media/image21.png" style="width:5.90764in;height:2.80278in"></a></p>
<p><strong>Figura 9.2:</strong> <em>Resultados del Experimento 1. A) Curvas visuales de percepción de distancia para ambas salas en el Experimento 1. Se muestran respuestas medias (+/- SEM) en función de la distancia al objetivo: cámara anecoica (An) como sala roja y reverberante (Rev ) en azul. La línea negra punteada indica un rendimiento perfecto. B) Volumen percibido medio (+/- SEM) para cada habitación. C) Cada caja transparente corresponde a las dimensiones individuales percibidas (anchura, longitud y altura) para cada condición (cámara anecoica: sección superior, en rojo; sala reverberante: sección inferior, en azul). Para cada habitación, la caja en líneas negras sólidas representa el promedio de cada dimensión (tomada por separado) entre los sujetos.</em></p>
</section>
<section id="experimento-2" class="level3" data-number="9.5.2">
<h3 data-number="9.5.2" class="anchored" data-anchor-id="experimento-2"><span class="header-section-number">9.5.2</span> Experimento 2</h3>
<p>Se realizó un segundo experimento para estudiar si el contraste auditivo, dado por la exposición consecutiva a dos habitaciones con características auditivas extremadamente diferentes, tuvo efecto en la percepción del tamaño de la habitación y, por lo tanto, en la distancia percibida de los objetivos visuales. Para ello, los sujetos del Grupo 1 repitieron la tarea de PVD, pero en la sala reverberante (es decir, pasaron de la cámara anecoica a la sala reverberante, a la que se hará referencia como A → R) mientras que los sujetos del Grupo 2 repitieron la tarea de PVD en la cámara anecoica (es decir, pasaron de la sala reverberante a la cámara anecoica, denominada R → A). El Experimento 2 se realizó pocos minutos después de completar el Experimento 1, siguiendo exactamente el mismo procedimiento que en la primera habitación (ver <em>Métodos</em>), y con los mismos sujetos. En particular, las instrucciones de la tarea se repitieron a través del altavoz, al igual que antes en el Experimento 1. En este punto, los sujetos fueron capaces de experimentar el fuerte contraste auditivo entre ambas salas debido a sus tiempos de reverberación extremadamente diferentes. Las respuestas también se hicieron verbalmente, contribuyendo así a la experiencia auditiva del entorno.</p>
<p>De manera similar al Experimento 1, se observó un efecto significativo de la habitación sobre el tamaño de la habitación percibida (Fig. 9.3c: volumen promedio percibido de la habitación, y Figura 9.3d: longitud, ancho y altura percibidos). Independientemente del orden de exposición, los sujetos dentro de cada grupo percibieron la habitación reverberante de mayores dimensiones que la cámara anecoica [Grupo 1, A→R: <em>t</em>(36) = 5.47, <em>p</em> = 1.8 x 10<sup>-6</sup>, razón media = 3,02; Grupo 2, R→A: <em>t</em>(37) = 3.85, <em>p</em> = 2.3 x 10<sup>-4</sup>, razón media = 1.64]. Por otra parte, la comparación entre los grupos mostró que, en la segunda exposición, la sala reverberante se percibió con mayores dimensiones que la cámara anecoica [t (73) = 3,26, p = 8,40 x 10-4, razón media = 2,89]. Es interesante notar que la diferencia fue mayor que la reportada en el Experimento 1 (razón media = 1,71), lo que sugiere que la exposición previa a una habitación con características acústicas opuestas influye en la percepción del tamaño de la habitación.</p>
<p>El paso siguiente consistió en analizar si el tamaño de la habitación percibido tenía alguna influencia en la PVD. La Figura 9.3 muestra la distancia media percibida (+/- SEM) como una función de la distancia objetivo para el Grupo 1 (A → R, Figura 9.3a) y 2 (R → A, Figura 9.3b). Comparamos la respuesta de cada grupo con las respuestas obtenidas por sí mismas en el Experimento 1 mediante el análisis de varianza de medidas repetidas. Contrariamente al Experimento 1, la sala no mostró un efecto significativo sobre la PVD. Los participantes de cada grupo percibieron los objetivos a distancias similares en comparación a las reportadas en el Experimento 1 [Grupo 1: F (1,36) = 0,0273, p = 0,87; Grupo 2: F (1,37) = 4,06, p = 0,051]. La distancia al objetivo fue significativa [Grupo 1: F (4,144) = 379, p &lt;0,001; Grupo 2: F (4,148) = 430, p &lt;0,001], mientras que la interacción entre el espacio y la distancia objetivo no fue significativa [Grupo 1: F (4,144) = 1,41, p = 0,24; Grupo 2: F (4, 148) = 1,97, p = 0,12].</p>
<p>Aunque no observamos una diferencia global en la respuesta de PVD en ninguno de los grupos, si observamos que los sujetos del Grupo 2 (R → A) tienden a comprimir sus respuestas para los dos objetivos más alejados, lo cual podría ser la causa de la significancia marginal obtenida en la ANOVA para la sala (p = 0,051) para este grupo. Los resultados muestran que las claves visuales situadas a D = 5 y 6 m se percibieron más lejanas en la habitación reverberante que en la cámara anecoica [5 m: t (37) = 2,76, p = 0,0045 &lt;0,01, razón media = 1,12; 6 m: t (37) = 2,39, p = 0,011 &lt;0,02, razón media = 1,10; ambas comparaciones tuvieron su importancia después de aplicar la [corrección de Holm-Bonferroni para comparaciones múltiples].</p>
<p>A continuación probamos la asociación entre MDP y el volumen percibido de la habitación. Curiosamente, el MDP correlacionó positivamente con el volumen percibido para el Grupo 2 (R → A, cámara anecoica, r = 0.67 con p = 4.7 x 10-6) pero no correlacionó con el Grupo 1 (A → R, sala reverberante, p = 0.18; Véase la Figura 9.4). Este último resultado es consistente con la presencia (en el Grupo 2) y ausencia (en el Grupo 1) de un efecto del contexto ambiental auditivo en la PVD, a pesar de que ambos grupos fueron capaces de percibir diferencias de tamaño entre salas.</p>
<p>Con el objetivo de explicar estas observaciones, se planteó la hipótesis de que una vez que el sujeto se acostumbra a la tarea (durante el Experimento 1), el cambio del entorno auditivo (durante el Experimento 2) podría ser insuficiente para cambiar la distancia percibida en el anterior sesión, a menos que exista una contradicción entre la respuesta anterior (especialmente en distancias más largas) y la percepción presente del espacio. Esta hipótesis podría explicar el efecto diferencial observado para los sujetos del Grupo 2 (R → A), lo cuales pasaron de la sala reverberante a la anecoica y, por lo tanto, experimentaron una reducción del espacio percibido. Es posible además que las distancias percibidas más lejanas en la habitación reverberante durante el Experimento 1 pudieran estar más allá de los límites percibidos de la cámara anecoica durante el Experimento 2 y, por lo tanto, no podrían ser posibles. Los sujetos del Grupo 1, en cambio, experimentaron una expansión del espacio percibido y, por lo tanto, todas las distancias anteriormente percibidas fueron posibles bajo su percepción actual de la habitación, permaneciendo así inalteradas.</p>
<p><a href="../media/image22.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="../media/image22.png" style="width:5.62569in;height:4.44064in"></a></p>
<p><strong>Figura 9.3</strong>: <em>Resultados del Exp. 2 y comparación con el Exp. 1. a) Curvas de distancia (respuesta media +/- SEM en función de la distancia al objetivo) para el Grupo 1. Los sujetos pasaron de la cámara anecoica (Exp. 1, línea punteada) a la Reverberante (Exp. 2, línea continua). B) igual que el anterior para el Grupo 2. Los sujetos pasaron de la sala reverberante (Exp. 1, línea punteada) a la cámara anecoica (Exp. 2, línea continua). C) Promedio de volumen percibido para cada habitación en ambos experimentos. Los datos de cada grupo se unieron con líneas punteadas. D) Cada caja transparente corresponde a las dimensiones individuales percibidas (anchura, longitud y altura) de cada condición (cámara anecoica: sección izquierda, en rojo, sala reverberante: sección derecha, en azul). Para cada habitación, la caja en líneas negras sólidas representa el promedio de cada dimensión (tomada por separado) entre los sujetos.</em></p>
<p>Esta hipótesis fue probada mediante el cálculo del porcentaje de sujetos cuya distancia máxima percibida fue mayor que la longitud informada de la habitación. Nos referiremos a esta magnitud como índice de incompatibilidad: MDP ≥ Longitud. Aplicando esta fórmula a los datos obtenidos para cada grupo en cada una de las habitaciones, obtuvimos un valor basal para los índices de incompatibilidad. Es decir, el porcentaje de respuestas obtenidas en cada habitación donde la MDP fue mayor que la longitud percibida. Esto dio como resultado un valor relativamente bajo (media = 14,7% con IC del 95% = +/- 3,4%). A continuación, aplicamos la fórmula a los datos de cada grupo en ambas salas: MDP (Exp. 1) ≥ Longitud (Exp. 2). Para el Grupo 1 (A → R) obtuvimos un valor igual a 8,1%, el valor más bajo entre las condiciones. Estos sujetos mantuvieron las respuestas de PVD entre salas pero informaron un aumento del tamaño de la habitación percibido en el Experimento 2 con respecto al Experimento 1. Siguiendo nuestra hipótesis, todas las distancias percibidas en el Experimento 1 fueron posibles en la sala más grande reportada en Experimento 2. Por el contrario, los sujetos del Grupo 2 (R → A) mostraron valor más alto de todas las condiciones . Este valor también fue significativamente diferente en comparación con el valor basal [t (3) = 8,18, p = 0,0038]. Esto implica que las distancias máximas reportadas en el Experimento 1 fueron mayores que la longitud percibida de la sala en el Experimento 2, lo que las hace contradictorias con la habitación percibida. Esto hace plausible que, durante el Experimento 2, los sujetos del Grupo 2 comprimieron sus respuestas para los dos objetivos más alejados a fin de hacerlos coincidir con el tamaño auditivo percibido del nuevo cuarto. De hecho, el índice de incompatibilidad de los sujetos del Grupo 2 en la cámara anecoica fue del 13,2%, lo cual indica que efectivamente ajustaron sus respuestas al tamaño de la habitación percibida bajo la nueva condición.</p>
<p><a href="../media/image23.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="../media/image23.png" style="width:5.90764in;height:4.94583in"></a></p>
<p><strong>Figura 9.4</strong>. <em>Distancia máxima percibida individual (DMP) vs volumen de la sala percibido para ambos grupos (filas) en el experimento 1 y 2 (columnas). Para cada condición, reportamos el coeficiente de correlación entre ambas magnitudes. Todos los grupos mostraron una correlación positiva con la excepción del grupo 1 en la cámara anecoica (Experimento 2). La línea roja indica el mejor ajuste lineal para los datos.</em></p>
</section>
</section>
<section id="discusión" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="discusión"><span class="header-section-number">9.6</span> Discusión</h2>
<p>Los experimentos aquí presentados demuestran que el contexto auditivo afecta a la distancia percibida de las claves luminosas ubicadas en un entorno de completa oscuridad. En el Experimento 1 los participantes ubicados en la sala reverberante percibieron todos los objetivos más alejados que los ubicados en la cámara anecoica. Esta observación de diferencias de PVD la atribuimos a las diferencias acústicas entre ambas salas. Tal afirmación se basa en las condiciones controladas del experimento: (i) los sujetos no tuvieron conocimiento previo de las características de la habitación y se encontraban en la misma posición relativa dentro de cada habitación; (ii) las distancias de prueba y los montajes fueron idénticos en ambas salas; y (iii) las habitaciones estuvieron situadas una frente a la otra, por lo que la información propioceptiva adquirida por los sujetos fue idéntica.</p>
<p>El efecto del ambiente auditivo en la PVD parece ser inducido por diferencias en las señales de reverberación relacionadas con la percepción auditiva del tamaño de la habitación. De forma consistente, los sujetos percibieron la habitación reverberante de mayor tamaño que la habitación anecoica. Este resultado concuerda con muchos estudios previos que informaron una correlación positiva entre el nivel de reverberación y percepción de tamaño de la habitación (Alais y Burr, 2004; Gajewsky, 2014). La hipótesis de la relación entre el tamaño de la habitación percibido y la percepción de la distancia se encuentra presente en diversos estudios (Radeau, 1974; Alais y Burr, 2004; Gajewsky, 2014) . En esta línea, Kolarik et al.&nbsp;(2013) encontraron una correlación positiva entre la percepción de la distancia auditiva y la percepción auditiva del tamaño de la habitación a través de señales de reverberación.</p>
<p>Siguiendo este razonamiento argumentamos que, en las condiciones utilizadas en los experimentos, la falta de conocimiento previo de la sala, combinada con la ausencia completa de señales visuales ambientales, indujo a los participantes a calibrar su respuesta (distancia percibida) a una habitación cuyo tamaño podría percibirse utilizando principalmente la modalidad auditiva. En primer lugar, esta hipótesis es apoyada por el hecho de que los objetivos fueron percibidos a una mayor distancia en la sala que se percibió con mayores dimensiones. En segundo lugar, encontramos que la distancia percibida del objetivo más distante y el volumen percibido de la habitación estuvieron correlacionados positivamente.</p>
<p>En el Experimento 2, los sujetos de ambos grupos repitieron la misma tarea de PVD, pero en la otra sala de pruebas. Con base en los hallazgos obtenidos en el Experimento 1, esperábamos que los sujetos informaran las distancias percibidas de acuerdo con el nivel de reverberación de cada habitación, asignando distancias más largas a medida que aumentaba la reverberación. De hecho, esperábamos un mayor efecto de la sala en la PVD debido al alto contraste auditivo experimentado después de los vestuarios. Sin embargo, esto no se observó. Al comparar los resultados dentro de cada grupo, los sujetos no ajustaron sistemáticamente sus respuestas al nivel de reverberación de la sala, a pesar de que percibieron diferencias significativas en el volumen de la habitación al pasar de una habitación a la otra. En cambio, los sujetos respondieron casi de la misma manera en que lo hicieron en el Experimento 1.</p>
<p>Una posible explicación de este resultado es que incluso cuando los resultados del Experimento 1 muestran que el contexto auditivo influyó en la respuesta, la distancia percibida fue modulada principalmente por las señales visuales proporcionadas por los objetivos. Por lo tanto, es posible que, como los sujetos realizaron la tarea en la primera sala, se desarrolló una fuerte asociación entre las señales visuales y la percepción de distancia. Dado que tanto los objetivos como las distancias de prueba fueron idénticos en ambos experimentos, y que en general las señales visuales son más confiables que las auditivas, es posible que el cambio del contexto auditivo durante la segunda exposición podría ser insuficiente para cambiar la asociación anterior entre las señales visuales y las respuestas. Esto podría haber sido favorecido también por la familiarización previa con el estímulo (ver <em>Métodos</em>), y por el corto intervalo de tiempo entre experimentos.</p>
<p>Para que sucediera lo antedicho, los participantes debieron retener en su memoria estas asociaciones durante el tiempo transcurrido entre el final del Experimento 1 y el comienzo del Experimento 2. Estudios previos de PVD han reportado que la información visual relacionada con la distancia a un objeto puede almacenarse con precisión en la memoria. Por ejemplo, los sujetos pueden ver a un objetivo a una distancia de hasta 20 m o más, y luego caminar hasta ella de manera bastante precisa con los ojos vendados (Thomson, 1983, Fukusima et al., 1997). Finalmente, Calcagno et al.&nbsp;(2012) mostró que los sujetos pueden almacenar en su memoria una representación visual del entorno que mejora, minutos después, la percepción de distancia de fuentes sonoras. Estos resultados sugieren que es posible que la información visual obtenida en el Experimento 1 afecte la respuesta durante el Experimento 2. Una pregunta interesante que surge de este hecho es ¿cuánto tiempo esta información puede ser almacenada en memoria antes de degradarse?. No sabemos qué resultados se podrían haber obtenido si el Experimento 2 se hubiese realizado unas horas o pocos días después del Experimento 1. Se necesitan estudios adicionales para conocer el curso temporal de este efecto.</p>
<p>Es interesante observar que las únicas discrepancias entre el Experimento 1 y el Experimento 2 fueron observadas en las respuestas de los sujetos del Grupo 2 (R → A). Estos sujetos mantuvieron sus respuestas sólo para los más próximos (2-4 m), pero no para los más alejados (5-6 m), los cuales se percibieron significativamente más cerca en la cámara anecoica que en la sala reverberante. Los sujetos de este grupo informaron una disminución del tamaño de la habitación en la cámara anecoica (comparada con la reportada previamente en la sala reverberante en el Experimento 1) lo suficiente como para ser incompatibles con las distancias más lejanas percibidas previamente en el Experimento 1. Esto se reflejó claramente en el análisis de incompatibilidad entre MDP y el tamaño de la habitación percibida, para el cual el Grupo 2 mostró el mayor valor del índice de incompatibilidad entre las condiciones. Dado este hecho, hipotetizamos que los sujetos retuvieron sus respuestas de la tarea anterior de PVD siempre que fueran compatibles con la actual percepción actual del entorno, es decir, los objetivos deberían ser percibidos dentro de la habitación percibida, caso contrario, la PVD estará sesgada hacia los límites percibidos de la habitación.</p>
<p>Esta hipótesis es apoyada por el análisis de correlación entre MDP y el volumen percibido de la habitación. Los sujetos del Grupo 2 ajustaron las distancias percibidas en el Experimento 1 (al menos para los dos objetivos más alejados) a una habitación cuyo tamaño percibido fue menor y, por lo tanto, muestran un coeficiente de correlación positivo entre ambas variables. Por otro lado, la ausencia de correlación para los sujetos del Grupo 1 resume el hecho de que los participantes fueron capaces de percibir diferencias de tamaño entre ambas salas sin asociar el tamaño del cuarto con las distancias reportadas previamente. El mismo resultado se observó en la correlación entre la pendiente de la respuesta y el volumen percibido de la habitación. Estos resultados concuerdan con la hipótesis de que, durante la segunda exposición, los participantes sólo percibieron cambios en la distancia del objetivo cuando fue incompatible con el tamaño de la habitación percibida.</p>
</section>
<section id="conclusiones" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="conclusiones"><span class="header-section-number">9.7</span> Conclusiones</h2>
<p>El efecto del contexto ambiental visual en la PVD ha sido reportado en varios estudios recientes (He et al., 2004; Iosa et al., 2012). Sin embargo, a diferencia de estudios anteriores, nuestros resultados muestran que la interacción entre el objeto visual y el entorno puede conformarse de una manera multimodal. Por otra parte, ninguno de los estudios anteriores consideró explícitamente el tamaño percibido del lugar en el que se realizó la tarea como factor influyente en la percepción visual a distancia. El único antecedente similar es el estudio de Kolarik et al.&nbsp;(2013) donde se observó una correlación positiva entre la distancia de una fuente y el tamaño percibido de una habitación a través de la modalidad auditiva. Aunque se necesita un estudio adicional para evaluar completamente esta relación, consideramos que los resultados aquí expuestos sugieren de forma robusta que la PVD depende de la percepción del tamaño del entorno donde se realiza el experimento.</p>
<p>En varios estudios anteriores se han demostrado interacciones audiovisuales multimodales. Cuando la información redundante acerca de alguna característica de un objetivo proviene de diferentes sentidos (integración multisensorial, véase: Proffit, 2008), la información se fusiona de tal manera que se conforma una percepción multisensorial coherente. Diversos estudios multimodales recientes han demostrado que ninguna modalidad tiene preponderancia sobre otras, sino que las percepciones unimodales se combinan teniendo en cuenta la calidad de la información proporcionada por cada una de ellas. Bajo las condiciones aquí utilizadas, las señales visuales del contexto se degradan hasta el punto de que la visión no da información sobre el contexto espacial. En consecuencia, los sujetos no tuvieron otra opción que crear una representación del entorno utilizando otras modalidades, utilizando principalmente señales auditivas.</p>
<p>Consideramos que el efecto aquí descrito es moderado (del orden del 20%), especialmente si se tiene en cuenta que el experimento se realizó bajo condiciones de reverberación muy diferentes y en ausencia de referencias visuales otorgadas por la sala. Presumiblemente, si el experimento se hubiera hecho en una habitación normalmente iluminada, la información visual habría anulado el efecto del entorno auditivo. Sin embargo, nuestros resultados argumentan que la información del contexto ambiental, obtenida a través de la modalidad auditiva, puede crear una representación espacial del entorno y que la misma puede servir como marco de referencia para la localización de objetivos percibidos a través de una modalidad sensorial diferente. Estudios previos de percepción auditiva de distancia han mostrado una relación similar entre la percepción del objeto y la del ambiente pero, en esos casos, el entorno visual influyó en la distancia perceptiva auditiva de una fuente. Por lo tanto, es razonable esperar un efecto similar en la percepción de distancia de la información espacial obtenida de otra modalidad sensorial (por ejemplo, propioceptivo).</p>
<p>La relación multimodal aquí observada puede servir como un modelo para entender de qué manera el cerebro codifica la información espacial a partir de varios sentidos. Por ejemplo, podría ayudar a guiar los experimentos con el objetivo de entender si los mapas cerebrales se forman en un área común del cerebro donde todas las modalidades contribuyen o si, en cambio, cada modalidad sensorial forma un mapa en una zona del cerebro específica a tal fin. La idea de un contexto ambiental multimodal en el que cada modalidad sensorial contribuye a construir nuestra percepción del entorno también podría utilizarse para mejorar el realismo de los entornos de realidad virtual. Sin embargo, se necesitan más investigaciones para comprender el alcance y las limitaciones de este tipo de interacción multimodal, así como la influencia de otras modalidades en la percepción visual a distancia.</p>
</section>
<section id="referencias-bibliográficas" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="referencias-bibliográficas"><span class="header-section-number">9.8</span> Referencias bibliográficas</h2>
<p>Alais, D., y Burr, D. The ventriloquist effect results from near-optimal bimodal integration. <em>Current biology</em> 14(3), 257-262 (2004).</p>
<p>Bingham, G. P., y Pagano, C. C. The necessity of a perception–action approach to definite distance perception: Monocular distance perception to guide reaching. <em>Journal of Experimental Psychology: Human Perception and Performance</em> <em>24</em>(1), 145 (1998).</p>
<p>Bingham, G. P., Pan, J. S., y Mon-Williams, M. A. Calibration is both functional and anatomical. <em>Journal of Experimental Psychology: Human Perception and Performance</em> <em>40</em>(1), 61 (2014).</p>
<p>Blake R. y Sekuler R. <em>Perception</em>, 5th edition. New York: McGraw-Hill (2006).</p>
<p>Bruggeman, H., y Warren, W. H. The direction of walking—but not throwing or kicking—is adapted by optic flow. Psychological science (2010).</p>
<p>Bülthoff, I., Bülthoff, H., y Sinha, P. Top-down influences on stereoscopic depth-perception. <em>Nature neuroscience</em> 1(3), 254-257 (1998).</p>
<p>Cabrera, D., Jeong, D., Kwak, H. J., Kim, J. Y., y Duckjingu, J. (2005, July). Auditory room size perception for modeled and measured rooms. In <em>Internoise, the 2005 Congress and Exposition on Noise Control Engineering</em>, Rio de Janeiro, Brazil, 7-10 August 2005.</p>
<p>Calcagno, E. R., Abregú, E. L., Eguía, M. C. y Vergara, R. O. The role of vision in auditory distance perception. <em>Perception</em> 41(2), 175-192. (2012).</p>
<p>Coats, R. O., Pan, J. S. y Bingham, G. P. Perturbation of perceptual units reveals dominance hierarchy in cross calibration. <em>Journal of Experimental Psychology: Human Perception and Performance</em> <em>40</em>(1), 328 (2014).</p>
<p>Creem‐Regehr, S. H., y Kunz, B. R. Perception and action. <em>Wiley Interdisciplinary Reviews: Cognitive Science</em> 1(6), 800-810 (2010).</p>
<p>Cutting, J.E., y Vishton, P. M. Perceiving layout and knowing distances: The integration, relative potency, and contextual use of different information about depth. In: <em>Handbook of Perception and Cognition</em>, Vol 5; Perception of Space and Motion.W. Epstein and S. J. Rogers, Eds., Academic Press, San Diego, CA, 69–117 (1995).</p>
<p>Da Vinci, L. <em>Trattato Della Pittura Di Leonardo Da Vinci</em>. Scritta da Raffaelle du Fresne. Paris: Langlois (1651).</p>
<p>Elliott, D. Continuous visual information may be important after all: A failure to replicate Thomson (1983). <em>Journal of Experimental Psychology: Human Perception and Performance</em> 12<em>.</em> 388-391 (1986).</p>
<p>Ernst, M. O., y Banks, M. S. Humans integrate visual and haptic information in a statistically optimal fashion. <em>Nature</em>, 415(6870), 429-433 (2002).</p>
<p>Ernst, M. O., y Bülthoff, H. H. Merging the senses into a robust percept. <em>Trends in cognitive sciences</em> 8(4), 162-169 (2004).</p>
<p>Foley, J. M. Binocular distance perception. <em>Psychological review</em> 87(5), 411 (1980).</p>
<p>Fukusima, S. S., Loomis, J. M. y Da Silva, J. A. Visual perception of egocentric distance as assessed by triangulation. <em>Journal of Experimental Psychology-Human Perception and Performance</em> 23(1), 86-100 (1997).</p>
<p>Fukusima, S. S., Loomis, J. M. y Da Silva, J. A. Visual perception of egocentric distance as assessed by triangulation. <em>Journal of Experimental Psychology-Human Perception and Performance</em> <em>23</em>(1), 86-100 (1997).</p>
<p>Gajewski, D. A., Philbeck, J. W., Wirtz, P. W. y Chichka, D. Angular declination and the dynamic perception of egocentric distance. Journal of Experimental Psychology: Human Perception and Performance 40(1), 361-377. doi: 10.1037/a0034394, (2014).</p>
<p>Gajewski, D. A., Wallin, C. P., y Philbeck y Gaze, J. W. Behavior and the perception of egocentric distance. <em>Journal of visión</em> 14(1), 1-19 (2014).</p>
<p>Giuliano, H. G., Velis, A. G. y Méndez, A. M. The reverberation chamber at the Laboratorio de Acústica y Luminotecnia of the Comisión de Investigaciones Científicas. <em>Applied Acoustics</em> 49(1), 71-83 (1996).</p>
<p>Gogel, W. C. Convergence as a cue to absolute distance. <em>The Journal of Psychology</em> 52(2), 287-301. (1961).</p>
<p>Hameed, S., Pakarinen, J., Valde, K. y Pulkki, V. Psychoacoustic cues in room size perception. In <em>Audio Engineering Society Convention 116</em>. Audio Engineering Society (2004).</p>
<p>Hay, J. C., Pick Jr, H. L. y Ikeda, K. Visual capture produced by prism spectacles. <em>Psychonomic science</em> 2(1-12), 215-216 (1965).</p>
<p>He, Z. J., Wu, B., Ooi, T. L., Yarbrough, G. y Wu, J. Judging egocentric distance on the ground: Occlusion and surface integration. <em>Perception</em> 33(7), 789-806 (2004).</p>
<p>Holm, S. A simple sequentially rejective multiple test procedure. <em>Scandinavian journal of statistics</em>, 65-70 (1979).</p>
<p>Howard, I. P. Perceiving in Depth, Volume 3: Other Mechanisms of Depth Perception, Oxford Psychology Series (2012).</p>
<p>Iosa, M., Fusco, A., Morone, G. y Paolucci, S. Walking there: environmental influence on walking-distance estimation. <em>Behavioural brain research</em> 226(1), 124-132. (2012).</p>
<p>King, A. J. Visual influences on auditory spatial learning. <em>Philosophical Transactions of the Royal Society of London B: Biological Sciences</em> <em>364</em>(1515), 331-339 (2009).</p>
<p>Kolarik, A. J., Pardhan, S., Cirstea, S. y Moore, B. C. Using acoustic information to perceive room size: effects of blindness, room reverberation time, and stimulus. <em>Perception</em> 42(9), 985-990 (2013).</p>
<p>Lappin, J. S., Shelton, A. L. y Rieser, J. J. Environmental context influences visually perceived distance. <em>Perception y psychophysics</em> 68(4), 571-581 (2006).</p>
<p>Lewald, J. Rapid adaptation to auditory-visual spatial disparity. <em>Learning y Memory</em> 9(5), 268-278 (2002).</p>
<p>Loomis, J. M. Looking down is looking up. <em>Nature</em>, 414(6860), 155-156 (2001).</p>
<p>Loomis, J. M. y Knapp, J. M. Visual perception of egocentric distance in real and virtual environments. <em>Virtual and adaptive environments</em> 11, 21-46 (2003).</p>
<p>Loomis, J. M., Da Silva, J. A., Fujita, N. y Fukusima, S. S. Visual space perception and visually directed action. <em>Journal of Experimental Psychology: Human Perception and Performance</em> 18(4), 906 (1992).</p>
<p>Loomis, J. M., Klatzky, R. L., Philbeck, J. W. y Golledge, R. G. Assessing auditory distance perception using perceptually directed action. <em>Attention, Perception, y Psychophysics</em> <em>60</em>(6), 966-980 (1998).</p>
<p>Loomis, J. M. y Philbeck, J. W. Measuring perception with spatial updating and action. In: <em>Embodiment, Ego-space, and Action</em>, R. L. Klatzky, B. MacWhinney, and M. Behrman, Eds., Psychology Press, New York, 1–43 (2008).</p>
<p>McGrath, R., Waldmann, T., y Fernström, M. Listening to rooms and objects. In <em>Audio Engineering Society Conference: 16th International Conference: Spatial Sound Reproduction</em>. Audio Engineering Society (1999).</p>
<p>Mershon, D. H., Ballenger, W. L., Little , A. D., McMurtry, P. L., y Buchanan, J. L. Effects of room reflectance and background noise on perceived auditory distance. <em>Perception</em> 18(3), 403-416 (1989).</p>
<p>Ono, H., Rogers, B. J., Ohmi, M. y Ono, M. E. Dynamic occlusion and motion parallax in depth perception. <em>Perception</em> 17(2), 255-266 (1988).</p>
<p>Pan, J. S., Coats, R. O., y Bingham, G. P. Calibration is action specific but perturbation of perceptual units is not. <em>Journal of Experimental Psychology: Human Perception and Performance</em> <em>40</em>(1), 404 (2014).</p>
<p>Pavani, F., Spence, C., y Driver, J. Visual capture of touch: Out-of-the-body experiences with rubber gloves. <em>Psychological science</em> 11(5), 353-359 (2000).</p>
<p>Philbeck, J. W., y Loomis, J. M. Comparison of two indicators of perceived egocentric distance under full-cue and reduced-cue conditions. <em>Journal of Experimental Psychology: Human Perception and Performance</em> 23(1), 72 (1997).</p>
<p>Proffitt, D. R. An action-specific approach to spatial perception. Embodiment, ego-space, and action. 179-202 (2008).</p>
<p>Proffitt, D.R. y Caudek, C. Depth perception and the perception of events. In: <em>Handbook of Psychology: Vol. 4 Experimental Psychology</em>, A. F. Healy and R. W. Proctor, Eds., Wiley, New York, 213–236 (2002).</p>
<p>Qian, N. Binocular disparity and the perception of depth. <em>Neuron</em> 18(3), 359-368 (1997).</p>
<p>Radeau, M., y Bertelson, P. The after-effects of ventriloquism. <em>The Quarterly journal of experimental psychology</em>, 26(1), 63-71 (1974).</p>
<p>Recanzone, G. H. Rapidly induced auditory plasticity: the ventriloquism aftereffect. <em>Proceedings of the National Academy of Sciences</em> 95(3), 869-875. (1998).</p>
<p>Rieser, J. J., Pick, H. L., Ashmead, D. H., y Garing, A. E. Calibration of human locomotion and models of perceptual-motor organization. <em>Journal of Experimental Psychology: Human Perception and Performance</em> <em>21</em>(3), 480 (1995).</p>
<p>Sandvad, J. Auditory perception of reverberant surroundings. <em>The Journal of the Acoustical Society of America</em> 105(2), 1193-1193 (1999).</p>
<p>Semmlow, J. L. y Heerema, D. The role of accommodative convergence at the limits of fusional vergence. <em>Investigative ophthalmology y visual science</em>, 18(9), 970-976 (1979).</p>
<p>Sousa, R., Brenner, E. y Smeets, J. B. J. A new binocular cue for absolute distance: Disparity relative to the most distant structure. <em>Vision research</em>, 50(18), 1786-1792 (2010).</p>
<p>Stefanucci, J. K., Proffitt, D. R., Banton, T. y Epstein, W. Distances appear different on hills. <em>Perception y Psychophysics</em> 67(6), 1052-1060 (2005).</p>
<p>Thomson, J. A. Is continuous visual monitoring necessary in visually guided locomotion? <em>Journal of Experimental Psychology: Human Perception and Performance</em> 9(3), 427 (1983).</p>
<p>Thomson, J. A. Is continuous visual monitoring necessary in visually guided locomotion?. <em>Journal of Experimental Psychology: Human Perception and Performance</em> <em>9</em>(3), 427 (1983).</p>
<p>Velis, A. G., Giuliano, H. G., y Méndez, A. M. The anechoic chamber at the Laboratorio de acústica y luminotecnia CIC. <em>Applied Acoustics</em> 44(1), 79-94 (1995).</p>
<p>Welch, R. B. <em>Perceptual modification: Adapting to altered sensory environments</em>. Elsevier (2013).</p>
<p>Witt, J. K., Stefanucci, J. K., Riener, C. R. y Proffitt, D. R. Seeing beyond the target: Environmental context affects distance perception. <em>Perception</em>, 36(12), 1752-1768 (2007).</p>
<p>Wu, B., Ooi, T. L., y He, Z. J. Perceiving distance accurately by a directional process of integrating ground information. <em>Nature</em> 428(6978), 73-77 (2004).</p>
<p>Zahorik, P. Estimating sound source distance with and without vision. <em>Optometry &amp; Vision Science</em> 78(5), 270-275 (2001).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/08-metodo-respuesta.html" class="pagination-link" aria-label="Evaluación del método de respuesta de localización directa para medir la percepción auditiva de distancia">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Evaluación del método de respuesta de localización directa para medir la percepción auditiva de distancia</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/10-ciencia-arte.html" class="pagination-link" aria-label="Interdisciplina entre ciencia y arte">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Interdisciplina entre ciencia y arte</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Dr. Ezequiel Abregú
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>